# Secure Federated learning 
This notebook is an experiment which attempts to Secure Federated learning by unlearning malicious client.
To do this, at each round of federated training, each client keeps a copy of the version of their model after training.To do this, at each round of federated training, each client keeps a copy of the version of their model after training.


<p float="left" align="middle">
  <img src="/Secure_FederatedLearning/result_plot.png" width="99%">
</p>
